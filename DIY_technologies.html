<!-- Template started by Simon Bird (s3916032)
     If you're using this template, make sure  _not_ to change me! You could get done! Really! -->
<!DOCTYPE html>
<html lang="en-au" dir="ltr">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <link rel="stylesheet" href="style.css">
    <title>Team Bootleggers | Project</title>
  </head>
  <body>
    <!-- Main title goes here -->
    <header>
      <img src="img/bootleggers.png" alt="Team Bootleggers Logo"/>
      <a id="top"></a>
    </header>
    <nav id="breadcrumb-container">
      <!-- Breadcrumb (reduce z-index by 1 each button)-->
      <div style="z-index:4"><a href="./index.html">Home</a></div>
      <div style="z-index:3"><a href="./About_Us.html">About Us</a></div>
      <div style="z-index:2"><a href="./industry.html">Careers</a></div>
      <div style="z-index:1"><a href="./Team Profile.html">Team Profile</a></div>
    </nav>
    <div class="main-header">
      <h2>Welcome to our Team Website</h2>
    </div>
    <div class="main-container">
      <!-- title header can help with subsections -->
      <div class="sub-container">
      <h3><a class="sub-button" href="./tech.html">Back to Technology</a></h3>
      </div>
      <br><br>
      <header class="sub-header">
        <h2>Machine Learning</h2>
      </header>
      <div class="sub-container">
        <p>Machine learning is an application of artificial intelligence (AI) that focusses on utilizing data and implementing algorithms to achieve outcomes that have not already been programmed into the system. This means the computer system learns (or studies) how to make accurate predictions and reach outcomes without the need for human intervention or assistance.  The learning material or prescribed text in this case is data, and lots of it. The key takeaway here is that unlike most programs that have been written by humans the system has not been explicitly told what the outcome should be. Instead, it has been taught how to utilise the data (machine learning) in order to be able to reach solutions independently.  As the algorithm iterates it continuously updates autonomously, that is without further human intervention on the programming side. Thus as more and more data is analysed and as more and more results are produced the algorithm’s accuracy also continuously improves (Tamir, M 2020). If you would like to learn more this website is a great visual learning representation of machine learning. http://www.r2d3.us/visual-intro-to-machine-learning-part-1/ Tere are three main categories of machine learning methods that exist today. They are supervised machine learning, unsupervised machine learning and semi-supervised machine learning. Another model exists that does not train itself utilising sample data but rather employs a trial-and-error approach to learn. This is known as reinforcement machine learning. Servised machine learning uses datasets that have already been sorted by users (aka people) to be able to compare and evaluate the accuracy of the algorithm’s results. This labelled or structured data provides answers that the algorithm is then iteratively able to adjust towards. Unsupervised machine learning uses raw, unsorted data and the algorithm produces conclusions without any human intervention. This means the algorithm draws truly autonomous conclusions and can often lead to the discovery of hidden patterns in data. Semi supervised learning is happy medium between the two models mentioned previous. It uses both structured and unstructured data to help formulate a guideline for the algorithm to achieve independent outcomes. This allows algorithms to learn how to label and sort unstructured data where there is a shortage of labelled data to run a supervised model (Tamir, M 2020). </p>
      </div><br>
      <div class="sub-container">
        <h3>How does it work?</h3>
        <p>At its most basic level machine learning utilises statistical learning and optimisation methods in order for computers to analyse datasets and identify patterns (Tamir, M 2020). Now I could continue regaling you with complex terminology with a hope that you are able to understand it all. But a more fruitful exercise would be that of using a real-world implementation of machine learning that most of us are already familiar with to explain how it all happens.So, here’s hoping you use Netflix in some capacity. The application of machine learning here is the Netflix Recommendation Engine (NRE). There are three main components that a supervised machine-learning algorithm consists of, and we will discuss how this works in the NRE:</p>
        <p>A decision process. This is the essential output of the algorithm. There are a variety of calculations and other steps applied to the data available to return a ‘guess’. In the case of the NRE this is your ‘Recommended’ list. It will initially be populated by generalizved data that is not particularly specific to you as the engine has no personalized data to work with, yet. </p>
        <p> An error function. This is how the algorithm can determine how good its ‘guess’ was. This can be done by comparing to known examples or from direct feedback. Was the guess a ‘hit’ or a ‘miss’? Does the algorithm return movies that you have already watched (good guesses)? The ‘Like’ or ‘Dislike’ feature currently present in Netflix provides explicit feedback.</p>
        <p>An optimisation process. Here the algorithm compares hits and misses to update the decision process to provide more accurate guesses in the future. Watch a lot of sci-fi -> sci-fi carries more weight and vice versa.  Therefore, the more you use Netflix the more it adapts to your preferences and tastes in its recommendation list.</p>
        <p>An optimisation process. Here the algorithm compares hits and misses to update the decision process to provide more accurate guesses in the future. Watch a lot of sci-fi -> sci-fi carries more weight and vice versa.  Therefore, the more you use Netflix the more it adapts to your preferences and tastes in its recommendation list.  </p>
        <p>You might often hear of terms such as ‘deep learning’ and ‘neural networks’ used interchangeably with machine learning however it is important to note the distinctions between the different terms. The confusion can arise as each term is consequently a subdivision of the other team.  All three fall under the overarching field of Artificial Intelligence (AI). (See Fig. 1) Neural networks are complex algorithms that mimic the human brain. A neural network that has more than three layers can be considered a deep learning algorithm (IBM Cloud Education, 2020). Deep learning is subdivision of machine learning. There are 2 aspects in how it defers from classical or ‘non-deep’ machine learning, how the algorithm learns and how much data is utilised. Deep learning falls under unsupervised machine learning. Thus it has to utilise much larger data sets as there are is no structured data to rely on. The amount of data in this case is both a limiting and enabling factor. Lex Fridman mentioned it as ‘scalable machine learning’ (Fridman, L 2019).  Classical, ‘non-deep’ or simply machine learning is more dependent on human intervention to learn. The data being use has already been sorted by users and thus the conclusions will often be more accurate but the amount of data available will be limited and dependent on human intervention.  </
        <h3>Current Applications </h3>
        <p>Although machine learning has been around since the 1950’s (Marr, B 2016), the amount of raw data that is being generated every day has meant that machine learning has exploded in interest of late. Furthermore the primary factor in expanding the capabilities of machine learning has been the advancements in raw processing power that has steadily improved year after year (Heath, N 2020). Still, it is important to bear in mind that in the machine learning world data is key, data is king. In today’s world machine learning is utilised in most aspects of everyday life. Chatbots you unknowingly interact with, Google reverse image search, speech recognition in phones, search recommendation engines, email spam detection are but a small number of the numerous applications of machine learning. Now this might seem like simple stuff to you so here are two applications of machine learning that are on the cutting edge: </p>
        <h3>Tesla Autopilot</h3>
        <p>Tesla is arguably at the forefront of self-driving technology and they rely on deep learning algorithms to power their Autopilot AI technology. They employ both neural network and deep learning algorithms to enable their cars to drive autonomously. Tesla also cross evaluate across their entire fleet so that every drive adds data that benefits all Tesla drivers. ‘A full build of Autopilot neural networks involves 48 networks that take 70,000 GPU hours to train. Together, they output 1,000 distinct tensors (predictions) at each timestep.’ (Tesla n. d., para 3) . </p>
        <h3>Google Translation Tech </h3>
        <p>Google introduced Transformer language models in 2017. This model takes a new approach to natural language processing (NLP). Previously language translators considered all the words of a sentence in sequential order. With the introduction of the Transformer language model, it started to consider all the words in a sentence at once which meant you could process much larger strings of information (S&P Global, 2021). Fast forward to today and Google have open sourced their latest Switch Transformer model. The new model outperformed their current T5 NLP model improving training times by 700%. A slight caveat is the much higher hardware requirements the new technology requires but in due time it will be widely accessible (Alford, A 2021). With continued improvement of internet infrastructure, the possibilities for machine learning are only going to grow exponentially. With the advent of cloud computing and remote resource sharing a lot of the accessibility barriers to machine learning have begun to break down. Amazon, Microsoft and Google have all offer cloud computing services that contain their own machine learning models ready to be utilised for a variety of tasks. As the infrastructure for these technologies are implemented and improved world-wide soon most consumer grade hardware will possess the capability to carry out complicated machine learning tasks. Now while machine learning lies within the AI category it’s use isn’t necessarily to always achieve outcomes that humans are capable of. A lot of the current innovation is taking place within the deep learning subdivision of machine learning. The focus here is to be able to extrapolate information from data that would otherwise be ignored or missed due to traditional human constraints. ata scientist is often a role that is associated with machine learning. They could be considered competitors and with the advancements in machine learning you might imagine that data scientists might be phased out. In actuality the complete opposite is happening. The U.S. Bureau of Labour statistics predicts that the job outlook (predicted growth) of data scientists from 2020-30 is 22%. Compare that to the average growth rate for all occupations which sits at 8% (Bureau of Labor Statistics, 2021) you can see the demand for data scientists has never been greater and there is a very good reason for that. Machine learning is an enabling tool for data scientists. It eliminates a lot of the menial work for sorting and structuring data by automating it. This allows data scientists to focus on tailoring solutions to specific needs and communicating the results across to nontechnical personnel (Bowne-Anderson, H 2018). Thus the skills sets required of data scientists are likely to evolve but their role has never been more important. </p>
        <h3>Why Should I Care? </h3>
        <p>When it comes to real-world applications of machine learning the possibilities are endless. Data analysis is a key tool for almost every sector in society. For example, you analyse data when you try coffee at café’s and settle on one you like best. You probably don’t need machine learning to determine that outcome, but the point still stands. The possible applications of machine learning has a very, very high ceiling.  ‘The continued digitization of most every sector of society and industry means that an ever-growing volume of data will continue to be generated. The ability to gain insights from these vast datasets is one key to addressing an enormous array of issues — from identifying and treating diseases more effectively, to fighting cyber criminals, to helping organizations operate more effectively to boost the bottom line.’ (Tamir, M 2020, para. 22) .  If you use any form of modern technology chances are you have benefitted from machine learning some manner. It is omnipresent in the online-centred, data-generating machine that is today’s society. And as I mentioned earlier in the world of machine learning data is key, data is king. But data does come at a cost. The ethical implications of storing user generated data has brought to light a whole host of issues concerning data privacy. Many governments already have legislation regarding privacy in place however due to the rapid transformation of technology a lot of this legislation could be considered outdated. With new and improved methods of both accumulating and analysing data governments are legislating new rules to be able to utilise that information in the name of the greater good. In Australia, the Identify and Disrupt Bill was recently passed through both house of federal parliament.  In summary this bill allows law enforcement agencies the ability to monitor, collect, modify and delete data associated with online activity of suspected offenders. Anyone who assists the government in this manner is also protected from civil liability. (Abbott, C 2021) he argument for collecting data for associated benefits versus encroaching the privacy of users is somewhat of a modern-day problem. It has not been something that we are familiar in tackling and thus will require innovative and progressive solutions moving forward. At what point does something stop being beneficial but rather detrimental due to the associated personal privacy cost? This is a predicament indicative of the modern problems we face in society today and something that also pertinent to the broader application of machine learning. </p>
      </div><br>
    </div>
    <footer>
      <!-- Proprietary information abound -->
      <a href="#top">Back to top</a>
    </footer>
  </body>
</html>
